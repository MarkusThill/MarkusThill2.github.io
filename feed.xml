<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://markusthill.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://markusthill.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-10-03T21:30:54+00:00</updated><id>https://markusthill.github.io/feed.xml</id><title type="html">blank</title><subtitle>A small collection of notes on Machine Learning, Programming and Math. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">The Relationship between the Mahalanobis Distance and the Chi-Squared Distribution</title><link href="https://markusthill.github.io/mahalanbis-chi-squared/" rel="alternate" type="text/html" title="The Relationship between the Mahalanobis Distance and the Chi-Squared Distribution"/><published>2023-10-03T13:56:00+00:00</published><updated>2023-10-03T13:56:00+00:00</updated><id>https://markusthill.github.io/mahalanobis-chi-squared</id><content type="html" xml:base="https://markusthill.github.io/mahalanbis-chi-squared/"><![CDATA[<p>In practice, sometimes (multivariate) Gaussian distributions are used for anomaly detection tasks (assuming that the considered data is approx. normally distributed): the parameters of the Gaussian can be estimated using maximum likelihood estimation (MLE) where the maximum likelihood estimate is the sample mean and sample covariance matrix. After the estimating the parameters of the distribution one has to specify a critical value which separates the normal data from the anomalous data. Typically, this critical value is taken from the probability density function (PDF) in such a way that it is smaller than the PDF value of all normal data points in the data set. Then a new data point can be classified as anomalous if the value of the PDF for this new point is below the critical value. Hence, the critical value specifies a boundary which is used to separate normal from anomalous data. In the univariate case the boundary separates the lower and upper tails of the Gaussian from its center (mean). In the 2-dimensional case the boundary is an ellipse around the center and in higher dimensions the boundary can be described by an ellipsoid. But what do we do, if want to find a boundary in a way that separates the most unlikely 2% of the data points from a sample from the remaining 99%. In the univariate case, this scenario is simple: We just have to compute the first percentile (1% quantile) and 99th percentile. All points that end up in the specified tails would then be classified as anomalous. For the multivariate case this is not that straightforward any longer, since our boundary has to be described by an ellipsoid. However, there is a way out of this problem, which has to do with a so called Mahalanobis-distance, as we will see in the following.</p> <p>\( \def\matr#1{\mathbf #1} \def\tp{\mathsf T} \)</p> <h2 id="prerequisites">Prerequisites</h2> <h3 id="multiplication-of-a-matrix-with-its-transpose">Multiplication of a Matrix with its Transpose</h3> <p>Generally, the product of a \(n \times \ell\) matrix \(\matr A\) and a \(\ell \times p\) matrix \(\matr B\) is defined as:</p> \[(\matr A \matr B)_{ij}=\sum_{k=1}^m \matr A_{ik} \matr B_{kj}\] <p>Then, the multiplication of a matrix \(\matr A\) with its transpose \(\matr A^\tp\) can be written as:</p> \[\begin{align} (\matr A \matr A^\mathsf T)_{ij} &amp;= \sum_{k=1}^\ell \matr A_{ik} \matr A^\mathsf T_{kj} \\ &amp;= \sum_{k=1}^\ell \matr A_{ik} \matr A_{jk} \\ \matr A \matr A^\mathsf T &amp;= \sum_{k=1}^\ell \vec a_{k} \vec a_{k}^\tp \label{eq:matrixProductWithTranspose} \end{align}\] <p>where \(\vec a_{k}\) is the \(k\)th column vector of matrix \(\matr A\). Another trivial relation required later is as follows:</p> \[\begin{align} x &amp;= \vec a^\mathsf T \vec b \\ y &amp;= \vec b^\mathsf T \vec a = x^\mathsf T=x \\ xy &amp;= \vec a^\mathsf T \vec b \, \vec b^\mathsf T \vec a = x^2 \\ &amp;= (\vec a^\mathsf T \vec b)^2 \label{eq:multOfTwoSkalars} \end{align}\] <h3 id="inverse-of-a-matrix-product">Inverse of a Matrix-Product</h3> <p>\(\begin{align} (\matr{A} \matr B)^{-1} = \matr B^{-1}\matr A^{-1} \label{eq:inverseProduct} \end{align}\) since \(\begin{align} ( \matr A \matr B)(\matr B^{-1} \matr A^{-1}) &amp;= (\matr A(\matr B \matr B^{-1})) \matr A^{-1} \\ &amp;= ( \matr A\mathbf{I}) \matr A^{-1} \\&amp;= \matr A \matr A^{-1} \\&amp;= \mathbf{I} \end{align}\)</p> <h3 id="eigenvalues-and-eigenvectors">Eigenvalues and Eigenvectors</h3> <p>For a matrix \(\matr A\) solve: \(\begin{equation} \matr{A} \vec{u} = \lambda \vec{u} \end{equation}\)</p> <p>A value \(\lambda\) which fulfills the equation is called an eigenvalue of \(\matr A\) and the corresponding vector \(\vec\mu\) is called eigenvector. When the eigenvectors of \(\matr A\) are arranged in a matrix \(\matr U\), we have:</p> \[\begin{align} \matr{A} \matr{U} &amp;= \matr{U} \matr{\Lambda}\\ \matr{A} &amp;= \matr{U} \matr{\Lambda} \matr{U}^{-1} \label{eq:eigendecomp} \end{align}\] <p>where \(\matr \Lambda\) is a diagonal matrix containing the eigenvalues \(\lambda_i\) of the corresponding eigenvectors. This representation, where the matrix is represented in terms of its eigenvalues and eigenvectors is also called eigenvalue decomposition. For symmetric matrices \(\matr{A}\), the eigenvectors are orthogonal (orthonormal) and the matrix \(\matr{U}\) is orthogonal as well (the product with its transpose is the identity matrix). In this case \(\matr{U}^{-1}=\matr{U}^{T}\), and equation \(\eqref{eq:eigendecomp}\) can be written as:</p> \[\begin{align} \matr{A} &amp;= \matr{U} \matr{\Lambda} \matr{U}^{T} \end{align}\] <p>In this case, also the square root of \(\matr A\) (written here as \(\matr A^{\frac{1}{2}}\)) – such that \(\matr A^{\frac{1}{2}}\matr A^{\frac{1}{2}}=A\) – can be easily found to be:</p> \[\begin{align} \matr A^{\frac{1}{2}} &amp;= \matr{U} \matr{\Lambda}^{\frac{1}{2}} \matr{U}^{T} \label{eq:sqrtSymMatrix} \end{align}\] <p>since</p> \[\begin{align} \matr A^{\frac{1}{2}} \cdot \matr A^{\frac{1}{2}} &amp;= \matr{U} \matr{\Lambda}^{\frac{1}{2}} \matr{U}^{T} \matr{U} \matr{\Lambda}^{\frac{1}{2}} \matr{U}^{T} \\ &amp;=\matr{U} \matr{\Lambda}^{\frac{1}{2}} \matr I \matr{\Lambda}^{\frac{1}{2}} \matr{U}^{T} \\ &amp;= \matr{U} \matr{\Lambda} \matr{U}^{T} \\ &amp;= \matr A \end{align}\] <p>The eigenvalue decomposition of the inverse of a matrix \(\matr A\) can be computed as follows, using the relation described in equation \(\eqref{eq:inverseProduct}\) and the associative property of the matrix product:</p> \[\begin{align} \matr{A}^{-1} &amp;= \big( \matr U \matr \Lambda \matr U^{-1} \big) \\ &amp;= \big( \matr U^{-1} \big)^{-1} \matr \Lambda^{-1} \matr U^{-1}\\ &amp;= \matr U \matr \Lambda^{-1} \matr U^{-1}\\ &amp;= \matr U \matr \Lambda^{-1} \matr U^{T}\label{eq:eigenvalueInverse} \\ \end{align}\] <p>Note that \(\Lambda^{-1}\) is again a diagonal matrix containing the inverse eigenvalues of \(\matr{A}\).</p> <h3 id="linear-affine-transform-of-a-normally-distributed-random-variable">Linear Affine Transform of a Normally Distributed Random Variable</h3> <p>Assume we apply a linear affine transform to a random variable \(X \thicksim N(\vec \mu_x, \Sigma_x)\) with a mean vector \(\vec\mu_x\) and a covariance matrix \(\Sigma_x\) in order to create a new random variable \(Y\):</p> \[Y=\matr A X + \vec b.\] <p>One can compute the new mean \(\vec\mu_y\) and covariance matrix \(\Sigma_y\) for \(Y\):</p> \[\begin{align} \vec \mu_y &amp;= E \{ Y \} \\ &amp;=E \{\matr A X + \vec b \} \\ &amp;= \matr A E \{\matr X \} + \vec b \\ &amp;= \matr A \vec \mu_x + \vec b \label{eq:AffineLinearTransformMean} \\ \end{align}\] <p>and</p> \[\begin{align} \matr \Sigma_y &amp;= E \{ (Y - \vec \mu_y) (Y - \vec \mu_y)^\tp \} \\ &amp;= E \{ \big[(\matr A X + \vec b) - (\matr A \vec \mu_x + \vec b) \big] \big[(\matr A X + \vec b) - (\matr A \vec \mu_x + \vec b) \big]^\tp \} \\ &amp;= E \{ \big[\matr A (X - \vec \mu_x) \big] \big[\matr A (X - \vec \mu_x ) \big]^\tp \} \\ &amp;= E \{ \matr A (X - \vec \mu_x) (X - \vec \mu_x )^\tp \matr A^\tp \} \\ &amp;= \matr A E \{ (X - \vec \mu_x) (X - \vec \mu_x )^\tp \} \matr A^\tp\\ &amp;= \matr A \matr \Sigma_x \matr A^\tp \label{eq:AffineLinearTransformCovariance}\\ \end{align}\] <h2 id="quantile-estimation-for-multivariate-gaussian-distributions">Quantile Estimation for multivariate Gaussian Distributions</h2> <ul> <li>Calculating quantiles for multivariate normal distributions is not that trivial as in the one-dimensional case, since we cannot simply compute the integral in the tails of the distribution</li> <li>The quantiles in the bivariate case can be seen as ellipses, in higher dimensions as ellipsoids</li> <li>The Mahalanobis distance is an interesting measure to describe all points on the surface of an ellipsoid.</li> <li>More formal: The usual quantile definition requires a random variable: The p-quantile for a random distribution is the value that fulfills . In the case of a multivariate normal distribution we can take the squared Mahalanobis distance between a point of the multivariate normal distribution and its mean as such a random variable. Then the p-quantile computation will answer the following question: Which value is required so that a random point fulfills ? In other words, when we pick a random point from the distribution, it will have with probability p a squared Mahalanobis distance equal or smaller than . The set of points with forms an ellipsoid.</li> <li>In a naive solution one can use a Monte Carlo approach to sample the multivariate normal distribution and compute the quantile based on the Mahalanobis distances of the elements of the sample</li> <li>However, this Monte Carlo approach is rather computationally inefficient, especially if quantiles have to be computed very often</li> <li>One can show that the squared Mahalanobis distance of a Gaussian distribution is actually Chi-Square distributed.</li> </ul> <h3 id="empirical-results-suggesting-that-the-mahalanobis-distance-is-chi-square-distributed">Empirical Results suggesting that the Mahalanobis Distance is Chi-Square distributed</h3> <p>In a Quantile-Quantile Plot one can see that quantiles of the Mahalanobis distance of a sample drawn from a Gaussian distribution is very similar to the corresponding quantiles computed on the Chi-Square distribution. The following R-script shows this:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">Matrix</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span><span class="w">
</span><span class="n">DIM</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="w">
</span><span class="n">nSample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="w">

</span><span class="n">Posdef</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">ev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="n">Z</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">ncol</span><span class="o">=</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="o">^</span><span class="m">2</span><span class="p">))</span><span class="w">
  </span><span class="n">decomp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">qr</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="w">
  </span><span class="n">Q</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">qr.Q</span><span class="p">(</span><span class="n">decomp</span><span class="p">)</span><span class="w">
  </span><span class="n">R</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">qr.R</span><span class="p">(</span><span class="n">decomp</span><span class="p">)</span><span class="w">
  </span><span class="n">d</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="n">R</span><span class="p">)</span><span class="w">
  </span><span class="n">ph</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">abs</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="w">
  </span><span class="n">O</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Q</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="n">ph</span><span class="p">)</span><span class="w">
  </span><span class="n">Z</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">O</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="n">ev</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">O</span><span class="w">
  </span><span class="nf">return</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">Sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Posdef</span><span class="p">(</span><span class="n">DIM</span><span class="p">)</span><span class="w">
</span><span class="n">muhat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">DIM</span><span class="p">)</span><span class="w">


</span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">nSample</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">muhat</span><span class="p">,</span><span class="w"> </span><span class="n">Sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Sigma</span><span class="p">)</span><span class="w">
</span><span class="n">C</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">.5</span><span class="o">*</span><span class="nf">log</span><span class="p">(</span><span class="n">det</span><span class="p">(</span><span class="m">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">Sigma</span><span class="p">))</span><span class="w">
</span><span class="n">mahaDist2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mahalanobis</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">sample</span><span class="p">,</span><span class="w"> </span><span class="n">center</span><span class="o">=</span><span class="n">muhat</span><span class="p">,</span><span class="n">cov</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span><span class="w">

</span><span class="c1">#</span><span class="w">
</span><span class="c1"># Interestingly, the Mahalanobis distance of samples follows a Chi-Square distribution</span><span class="w">
</span><span class="c1"># with d degrees of freedom</span><span class="w">
</span><span class="c1">#</span><span class="w">
</span><span class="n">pps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">100</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="m">100+1</span><span class="p">)</span><span class="w">
</span><span class="n">qq1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sapply</span><span class="p">(</span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pps</span><span class="p">,</span><span class="w"> </span><span class="n">FUN</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="n">quantile</span><span class="p">(</span><span class="n">mahaDist2</span><span class="p">,</span><span class="w"> </span><span class="n">probs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">})</span><span class="w">
</span><span class="n">qq2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">  </span><span class="n">sapply</span><span class="p">(</span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pps</span><span class="p">,</span><span class="w"> </span><span class="n">FUN</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">qchisq</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">=</span><span class="n">ncol</span><span class="p">(</span><span class="n">Sigma</span><span class="p">))</span><span class="w">

</span><span class="n">dat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">qEmp</span><span class="o">=</span><span class="w"> </span><span class="n">qq1</span><span class="p">,</span><span class="w"> </span><span class="n">qChiSq</span><span class="o">=</span><span class="n">qq2</span><span class="p">)</span><span class="w">
</span><span class="n">p</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dat</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">geom_point</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">qEmp</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">qChiSq</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">xlab</span><span class="p">(</span><span class="s2">"Sample quantile"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">ylab</span><span class="p">(</span><span class="s2">"Chi-Squared Quantile"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">)</span></code></pre></figure> <p><img src="https://markusthill.github.io/images/Q-Q-Plot.png" alt="Picture description" class="image-center"/></p> <h3 id="the-squared-mahalanobis-distance-follows-a-chi-square-distribution-more-formal-derivation">The squared Mahalanobis Distance follows a Chi-Square Distribution: More formal Derivation</h3> <p>The Mahalanobis distance between two points \(\vec x\) and \(\vec y\) is defined as</p> \[d(\vec x,\vec y) = \sqrt{(\vec x -\vec y )^\tp \matr \Sigma^{-1} (\vec x - \vec y)}\] <p>Thus, the squared Mahalanobis distance of a random vector \(\matr X\) and the center \(\vec \mu\) of a multivariate Gaussian distribution is defined as: \(\begin{align} D = d(\matr X,\vec \mu)^2 = (\matr X -\vec \mu )^\tp \matr \Sigma^{-1} (\matr X - \vec \mu ) \label{eq:sqMahalanobis} \end{align}\)</p> <p>where \(\matr \Sigma\) is a \(\ell \times \ell\) covariance matrix and \(\vec \mu\) is the mean vector. In order to achieve a different representation of \(D\) one can first perform an eigenvalue decomposition on \(\matr \Sigma^{-1}\) which is (with Eq. \(\eqref{eq:eigenvalueInverse}\) and assuming orthonormal eigenvectors):</p> \[\begin{align} \matr \Sigma^{-1} &amp;= \matr U \matr \Lambda^{-1} \matr U^{-1} \\ &amp;= \matr U \matr \Lambda^{-1} \matr U^{T} \\ \end{align}\] <p>With Eq. \(\eqref{eq:matrixProductWithTranspose}\) we get:</p> \[\begin{align} \matr \Sigma^{-1} &amp;= \sum_{k=1}^\ell \lambda_k^{-1} \vec u_{k} \vec u_{k}^\tp \label{eq:SigmaInverseAsSum} \end{align}\] <p>where \(\vec u_{k}\) is the \(k\)th eigenvector of the corresponding eigenvalue \(\lambda_k\). Plugging \eqref{eq:SigmaInverseAsSum} back into \eqref{eq:sqMahalanobis} results in:</p> \[\begin{align} D &amp;= (\matr X -\vec \mu )^\tp \matr \Sigma^{-1} (\matr X - \vec \mu ) \\ &amp;= (\matr X -\vec \mu )^\tp \Bigg( \sum_{k=1}^\ell \lambda_k^{-1} \vec u_{k} \vec u_{k}^\tp \Bigg) (\matr X - \vec \mu ) \\ &amp;= \sum_{k=1}^\ell \lambda_k^{-1} (\matr X -\vec \mu )^\tp \vec u_{k} \vec u_{k}^\tp (\matr X - \vec \mu ) \end{align}\] <p>With Eq. \eqref{eq:multOfTwoSkalars} one gets:</p> \[\begin{align} D &amp;= \sum_{k=1}^\ell \lambda_k^{-1} \Big[ \vec u_{k}^\tp (\matr X - \vec \mu ) \Big]^2\\ &amp;= \sum_{k=1}^\ell \Big[ \lambda_k^{-\frac{1}{2}} \vec u_{k}^\tp (\matr X - \vec \mu ) \Big]^2\\ &amp;= \sum_{k=1}^\ell Y_k^2 \end{align}\] <p>where \(Y_k\) is a new random variable based on an affine linear transform of the random vector \(\matr X\). According to Eq. \eqref{eq:AffineLinearTransformMean} , we have \(\matr Z = (\matr X - \vec \mu ) \thicksim N(\vec 0,\Sigma)\). If we set \(\vec a_{k}^\tp = \lambda_k^{-\frac{1}{2}} \vec u_{k}^\tp\) then we get \(Y_k = \vec a_{k}^\tp \matr Z = \lambda_k^{-\frac{1}{2}} \vec u_{k}^\tp \matr Z\). Note that \(Y_k\) is now a random Variable drawn from a univariate normal distribution \(Y_k \thicksim N(0,\sigma_k^2)\), where, according to \eqref{eq:AffineLinearTransformCovariance}:</p> \[\begin{align} \sigma_k^2 &amp;= \vec a_{k}^\tp \Sigma \vec a_{k}\\ &amp;= \lambda_k^{-\frac{1}{2}} \vec u_{k}^\tp \Sigma \lambda_k^{-\frac{1}{2}} \vec u_{k} \\ &amp;= \lambda_k^{-1} \vec u_{k}^\tp \Sigma \vec u_{k} \label{eq:smallSigma} \end{align}\] <p>If we insert</p> \[\begin{align} \matr \Sigma &amp;= \sum_{j=1}^\ell \lambda_j \vec u_{j} \vec u_{j}^\tp \end{align}\] <p>into Eq. \eqref{eq:smallSigma}, we get: \(\begin{align} \sigma_k^2 &amp;= \lambda_k^{-1} \vec u_{k}^\tp \Sigma \vec u_{k} \\ &amp;= \lambda_k^{-1} \vec u_{k}^\tp \Bigg( \sum_{j=1}^\ell \lambda_j \vec u_{j} \vec u_{j}^\tp \Bigg) \vec u_{k} \\ &amp;= \sum_{j=1}^\ell \lambda_k^{-1} \vec u_{k}^\tp \lambda_j \vec u_{j} \vec u_{j}^\tp \vec u_{k} \\ &amp;= \sum_{j=1}^\ell \lambda_k^{-1} \lambda_j \vec u_{k}^\tp \vec u_{j} \vec u_{j}^\tp \vec u_{k} \\ \end{align}\)</p> <p>Since all eigenvectors \(\vec u_{i}\) are pairwise orthonormal the dotted products \(\vec u_{k}^\tp \vec u_{j}\) and \(\vec u_{j}^\tp \vec u_{k}\) will be zero for \(j \neq k\). Only for the case \(j = k\) we get: \(\begin{align} \sigma_k^2 &amp;= \lambda_k^{-1} \lambda_k \vec u_{k}^\tp \vec u_{k} \vec u_{k}^\tp \vec u_{k} \\ &amp;= \lambda_k^{-1} \lambda_k ||\vec u_{k}||^2 ||\vec u_{k}||^2 \\ &amp;= \lambda_k^{-1} \lambda_k ||\vec u_{k}||^2 ||\vec u_{k}||^2 \\ &amp;= 1, \end{align}\)</p> <p>since the the norm \(||\vec u_{k}||\) of a orthonormal eigenvector is equal to 1. The squared Mahalanobis distance can be expressed as:</p> \[\begin{align} D &amp;= \sum_{k=1}^\ell Y_k^2 \end{align}\] <p>where \(Y_k \thicksim N(0,1).\)</p> <p>Now the Chi-square distribution with \(\ell\) degrees of freedom is exactly defined as being the distribution of a variable which is the sum of the squares of \(\ell\) random variables being standard normally distributed. Hence, \(D\) is Chi-square distributed with \(\ell\) degrees of freedom.</p> <h3 id="derivation-based-on-the-whitening-property-of-the-mahalanobis-distance">Derivation based on the Whitening Property of the Mahalanobis Distance</h3> <p>Since the inverse \(\matr \Sigma^{-1}\) of the covariance matrix \(\matr \Sigma\) is also a symmetric matrix, its squareroot can be found – based on Eq. \eqref{eq:sqrtSymMatrix} – to be a symmetric matrix . In this case we can write the squared Mahalanobis distance as \(\begin{align} D &amp;= (\matr X -\vec \mu )^\tp \matr \Sigma^{-1} (\matr X - \vec \mu ) \\ &amp;= (\matr X -\vec \mu )^\tp \matr \Sigma^{-\frac{1}{2}} \matr \Sigma^{-\frac{1}{2}} (\matr X - \vec \mu )\\ &amp;= \Big( \matr \Sigma^{-\frac{1}{2}} (\matr X -\vec \mu ) \Big)^\tp \Big(\matr \Sigma^{-\frac{1}{2}} (\matr X - \vec \mu ) \Big) \\ &amp;= \matr Y^\tp \matr Y \\ &amp;= ||\matr Y||^2 \\ &amp;= \sum_{k=1}^\ell Y_k^2 \end{align}\)</p> <p>The multiplication \(\matr Y = \matr W \matr Z\), with \(\matr W=\matr \Sigma^{-\frac{1}{2}}\) and \(\matr Z= \matr X -\vec \mu\) is typically reffered to as a whitening transform, where in this case \(\matr W=\matr \Sigma^{-\frac{1}{2}}\) is the so called Mahalanobis (or ZCA) whitening matrix. \(\matr Y\) has zero mean, since \((\matr X - \vec \mu ) \thicksim N(\vec 0,\Sigma)\). Due to the (linear) whitening transform the new covariance matrix \(\matr \Sigma_y\) is the identity matrix \(\matr I\), as shown in the following (using the property in Eq. \eqref{eq:AffineLinearTransformCovariance}):</p> \[\begin{align} \matr \Sigma_y &amp;= \matr W \matr \Sigma \matr W^\tp \\ &amp;= \matr \Sigma^{-\frac{1}{2}} \matr \Sigma \Big( \matr \Sigma^{-\frac{1}{2}} \Big)^\tp \\ &amp;= \matr \Sigma^{-\frac{1}{2}} \Big(\matr \Sigma^{\frac{1}{2}}\matr \Sigma^{\frac{1}{2}} \Big) \Big( \matr \Sigma^{-\frac{1}{2}} \Big)^\tp \\ &amp;= \matr \Sigma^{-\frac{1}{2}} \Big(\matr \Sigma^{\frac{1}{2}}\matr \Sigma^{\frac{1}{2}} \Big) \matr \Sigma^{-\frac{1}{2}} \\ &amp;= \Big(\matr \Sigma^{-\frac{1}{2}} \matr \Sigma^{\frac{1}{2}} \Big) \Big(\matr \Sigma^{\frac{1}{2}} \matr \Sigma^{-\frac{1}{2}}\Big) \\ &amp;= \matr I \end{align}\] <p>Hence, all elements \(Y_k\) in the random vector \(\matr Y\) are random variables drawn from independent normal distributions \(Y_k \thicksim N(0,1)\), which leads us to the same conclusion as before, that \(D\) is Chi-square distributed with \(\ell\) degrees of freedom.</p>]]></content><author><name></name></author><category term="stats"/><category term="ml"/><category term="mahalanobis"/><category term="chi2"/><summary type="html"><![CDATA[The Relationship between the Mahalanobis Distance and the Chi-Squared Distribution]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://markusthill.github.io/%7B%22feature%22=%3E%221141s.jpg%22,%20%22credit%22=%3E%22Designed%20by%20onlyyouqj%20/%20Freepik%22,%20%22creditlink%22=%3E%22https://www.freepik.com%22%7D"/><media:content medium="image" url="https://markusthill.github.io/%7B%22feature%22=%3E%221141s.jpg%22,%20%22credit%22=%3E%22Designed%20by%20onlyyouqj%20/%20Freepik%22,%20%22creditlink%22=%3E%22https://www.freepik.com%22%7D" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">a post with bibliography</title><link href="https://markusthill.github.io/blog/2023/post-bibliography/" rel="alternate" type="text/html" title="a post with bibliography"/><published>2023-07-12T13:56:00+00:00</published><updated>2023-07-12T13:56:00+00:00</updated><id>https://markusthill.github.io/blog/2023/post-bibliography</id><content type="html" xml:base="https://markusthill.github.io/blog/2023/post-bibliography/"><![CDATA[<p>This post shows how to add bibliography to simple blog posts. If you would like something more academic, check the <a href="/blog/2021/distill/">distill style post</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="bib"/><summary type="html"><![CDATA[an example of a blog post with bibliography]]></summary></entry><entry><title type="html">a post with jupyter notebook</title><link href="https://markusthill.github.io/blog/2023/jupyter-notebook/" rel="alternate" type="text/html" title="a post with jupyter notebook"/><published>2023-07-04T12:57:00+00:00</published><updated>2023-07-04T12:57:00+00:00</updated><id>https://markusthill.github.io/blog/2023/jupyter-notebook</id><content type="html" xml:base="https://markusthill.github.io/blog/2023/jupyter-notebook/"><![CDATA[<p>To include a jupyter notebook in a post, you can use the following code:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/blog.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/blog.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
    {% jupyter_notebook jupyter_path %}
{% else %}
    <span class="nt">&lt;p&gt;</span>Sorry, the notebook you are looking for does not exist.<span class="nt">&lt;/p&gt;</span>
{% endif %}
{:/nomarkdown}
</code></pre></div></div> <p>Let’s break it down: this is possible thanks to <a href="https://github.com/red-data-tools/jekyll-jupyter-notebook">Jekyll Jupyter Notebook plugin</a> that allows you to embed jupyter notebooks in your posts. It basically calls <a href="https://nbconvert.readthedocs.io/en/latest/usage.html#convert-html"><code class="language-plaintext highlighter-rouge">jupyter nbconvert --to html</code></a> to convert the notebook to an html page and then includes it in the post. Since <a href="https://jekyllrb.com/docs/configuration/markdown/">Kramdown</a> is the default Markdown renderer for Jekyll, we need to surround the call to the plugin with the <a href="https://kramdown.gettalong.org/syntax.html#extensions">::nomarkdown</a> tag so that it stops processing this part with Kramdown and outputs the content as-is.</p> <p>The plugin takes as input the path to the notebook, but it assumes the file exists. If you want to check if the file exists before calling the plugin, you can use the <code class="language-plaintext highlighter-rouge">file_exists</code> filter. This avoids getting a 404 error from the plugin and ending up displaying the main page inside of it instead. If the file does not exist, you can output a message to the user. The code displayed above outputs the following:</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/blog.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>Note that the jupyter notebook supports both light and dark themes.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="jupyter"/><summary type="html"><![CDATA[an example of a blog post with jupyter notebook]]></summary></entry><entry><title type="html">a post with custom blockquotes</title><link href="https://markusthill.github.io/blog/2023/custom-blockquotes/" rel="alternate" type="text/html" title="a post with custom blockquotes"/><published>2023-05-12T19:53:00+00:00</published><updated>2023-05-12T19:53:00+00:00</updated><id>https://markusthill.github.io/blog/2023/custom-blockquotes</id><content type="html" xml:base="https://markusthill.github.io/blog/2023/custom-blockquotes/"><![CDATA[<p>This post shows how to add custom styles for blockquotes. Based on <a href="https://github.com/sighingnow/jekyll-gitbook">jekyll-gitbook</a> implementation.</p> <p>We decided to support the same custom blockquotes as in <a href="https://sighingnow.github.io/jekyll-gitbook/jekyll/2022-06-30-tips_warnings_dangers.html">jekyll-gitbook</a>, which are also found in a lot of other sites’ styles. The styles definitions can be found on the <a href="https://github.com/alshedivat/al-folio/blob/master/_sass/_base.scss">_base.scss</a> file, more specifically:</p> <div class="language-scss highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/* Tips, warnings, and dangers */</span>
<span class="nc">.post</span> <span class="nc">.post-content</span> <span class="nt">blockquote</span> <span class="p">{</span>
    <span class="k">&amp;</span><span class="nc">.block-tip</span> <span class="p">{</span>
    <span class="nl">border-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-tip-block</span><span class="p">);</span>
    <span class="nl">background-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-tip-block-bg</span><span class="p">);</span>

    <span class="nt">p</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-tip-block-text</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="nt">h1</span><span class="o">,</span> <span class="nt">h2</span><span class="o">,</span> <span class="nt">h3</span><span class="o">,</span> <span class="nt">h4</span><span class="o">,</span> <span class="nt">h5</span><span class="o">,</span> <span class="nt">h6</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-tip-block-title</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">&amp;</span><span class="nc">.block-warning</span> <span class="p">{</span>
    <span class="nl">border-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-warning-block</span><span class="p">);</span>
    <span class="nl">background-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-warning-block-bg</span><span class="p">);</span>

    <span class="nt">p</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-warning-block-text</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="nt">h1</span><span class="o">,</span> <span class="nt">h2</span><span class="o">,</span> <span class="nt">h3</span><span class="o">,</span> <span class="nt">h4</span><span class="o">,</span> <span class="nt">h5</span><span class="o">,</span> <span class="nt">h6</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-warning-block-title</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">&amp;</span><span class="nc">.block-danger</span> <span class="p">{</span>
    <span class="nl">border-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-danger-block</span><span class="p">);</span>
    <span class="nl">background-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-danger-block-bg</span><span class="p">);</span>

    <span class="nt">p</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-danger-block-text</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="nt">h1</span><span class="o">,</span> <span class="nt">h2</span><span class="o">,</span> <span class="nt">h3</span><span class="o">,</span> <span class="nt">h4</span><span class="o">,</span> <span class="nt">h5</span><span class="o">,</span> <span class="nt">h6</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-danger-block-title</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>A regular blockquote can be used as following:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt; This is a regular blockquote</span>
<span class="gt">&gt; and it can be used as usual</span>
</code></pre></div></div> <blockquote> <p>This is a regular blockquote and it can be used as usual</p> </blockquote> <p>These custom styles can be used by adding the specific class to the blockquote, as follows:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt; ##### TIP</span>
<span class="gt">&gt;</span>
<span class="gt">&gt; A tip can be used when you want to give advice</span>
<span class="gt">&gt; related to a certain content.</span>
{: .block-tip }
</code></pre></div></div> <blockquote class="block-tip"> <h5 id="tip">TIP</h5> <p>A tip can be used when you want to give advice related to a certain content.</p> </blockquote> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt; ##### WARNING</span>
<span class="gt">&gt;</span>
<span class="gt">&gt; This is a warning, and thus should</span>
<span class="gt">&gt; be used when you want to warn the user</span>
{: .block-warning }
</code></pre></div></div> <blockquote class="block-warning"> <h5 id="warning">WARNING</h5> <p>This is a warning, and thus should be used when you want to warn the user</p> </blockquote> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt; ##### DANGER</span>
<span class="gt">&gt;</span>
<span class="gt">&gt; This is a danger zone, and thus should</span>
<span class="gt">&gt; be used carefully</span>
{: .block-danger }
</code></pre></div></div> <blockquote class="block-danger"> <h5 id="danger">DANGER</h5> <p>This is a danger zone, and thus should be used carefully</p> </blockquote>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="blockquotes"/><summary type="html"><![CDATA[an example of a blog post with custom blockquotes]]></summary></entry><entry><title type="html">a post with table of contents on a sidebar</title><link href="https://markusthill.github.io/blog/2023/sidebar-table-of-contents/" rel="alternate" type="text/html" title="a post with table of contents on a sidebar"/><published>2023-04-25T14:14:00+00:00</published><updated>2023-04-25T14:14:00+00:00</updated><id>https://markusthill.github.io/blog/2023/sidebar-table-of-contents</id><content type="html" xml:base="https://markusthill.github.io/blog/2023/sidebar-table-of-contents/"><![CDATA[<p>This post shows how to add a table of contents as a sidebar.</p> <h2 id="adding-a-table-of-contents">Adding a Table of Contents</h2> <p>To add a table of contents to a post as a sidebar, simply add</p> <div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">toc</span><span class="pi">:</span>
  <span class="na">sidebar</span><span class="pi">:</span> <span class="s">left</span>
</code></pre></div></div> <p>to the front matter of the post. The table of contents will be automatically generated from the headings in the post. If you wish to display the sidebar to the right, simply change <code class="language-plaintext highlighter-rouge">left</code> to <code class="language-plaintext highlighter-rouge">right</code>.</p> <h3 id="example-of-sub-heading-1">Example of Sub-Heading 1</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h3 id="example-of-another-sub-heading-1">Example of another Sub-Heading 1</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h2 data-toc-text="Customizing" id="customizing-your-table-of-contents">Customizing Your Table of Contents</h2> <p>If you want to learn more about how to customize the table of contents of your sidebar, you can check the <a href="https://afeld.github.io/bootstrap-toc/">bootstrap-toc</a> documentation. Notice that you can even customize the text of the heading that will be displayed on the sidebar.</p> <h3 id="example-of-sub-heading-2">Example of Sub-Heading 2</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h3 id="example-of-another-sub-heading-2">Example of another Sub-Heading 2</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="toc"/><category term="sidebar"/><summary type="html"><![CDATA[an example of a blog post with table of contents on a sidebar]]></summary></entry><entry><title type="html">a post with audios</title><link href="https://markusthill.github.io/blog/2023/audios/" rel="alternate" type="text/html" title="a post with audios"/><published>2023-04-25T10:25:00+00:00</published><updated>2023-04-25T10:25:00+00:00</updated><id>https://markusthill.github.io/blog/2023/audios</id><content type="html" xml:base="https://markusthill.github.io/blog/2023/audios/"><![CDATA[<p>This is an example post with audios. It supports local audio files.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/audio/epicaly-short-113909.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="https://cdn.pixabay.com/download/audio/2022/06/25/audio_69a61cd6d6.mp3" controls=""/> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between video rows, after each row, or doesn't have to be there at all. </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="audios"/><summary type="html"><![CDATA[this is what included audios could look like]]></summary></entry><entry><title type="html">a post with videos</title><link href="https://markusthill.github.io/blog/2023/videos/" rel="alternate" type="text/html" title="a post with videos"/><published>2023-04-24T21:01:00+00:00</published><updated>2023-04-24T21:01:00+00:00</updated><id>https://markusthill.github.io/blog/2023/videos</id><content type="html" xml:base="https://markusthill.github.io/blog/2023/videos/"><![CDATA[<p>This is an example post with videos. It supports local video files.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/pexels-engin-akyurt-6069112-960x540-30fps.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/pexels-engin-akyurt-6069112-960x540-30fps.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""/> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between video rows, after each row, or doesn't have to be there at all. </div> <p>It does also support embedding videos from different sources. Here are some examples:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://www.youtube.com/embed/jNQXAC9IVRw" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://player.vimeo.com/video/524933864?h=1ac4fd9fb4&amp;title=0&amp;byline=0&amp;portrait=0" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </figure> </div> </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="videos"/><summary type="html"><![CDATA[this is what included videos could look like]]></summary></entry><entry><title type="html">displaying beautiful tables with Bootstrap Tables</title><link href="https://markusthill.github.io/blog/2023/tables/" rel="alternate" type="text/html" title="displaying beautiful tables with Bootstrap Tables"/><published>2023-03-20T18:37:00+00:00</published><updated>2023-03-20T18:37:00+00:00</updated><id>https://markusthill.github.io/blog/2023/tables</id><content type="html" xml:base="https://markusthill.github.io/blog/2023/tables/"><![CDATA[<p>Using markdown to display tables is easy. Just use the following syntax:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| Left aligned | Center aligned | Right aligned |
| :----------- | :------------: | ------------: |
| Left 1       | center 1       | right 1       |
| Left 2       | center 2       | right 2       |
| Left 3       | center 3       | right 3       |
</code></pre></div></div> <p>That will generate:</p> <table> <thead> <tr> <th style="text-align: left">Left aligned</th> <th style="text-align: center">Center aligned</th> <th style="text-align: right">Right aligned</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Left 1</td> <td style="text-align: center">center 1</td> <td style="text-align: right">right 1</td> </tr> <tr> <td style="text-align: left">Left 2</td> <td style="text-align: center">center 2</td> <td style="text-align: right">right 2</td> </tr> <tr> <td style="text-align: left">Left 3</td> <td style="text-align: center">center 3</td> <td style="text-align: right">right 3</td> </tr> </tbody> </table> <p></p> <p>It is also possible to use HTML to display tables. For example, the following HTML code will display a table with <a href="https://bootstrap-table.com/">Bootstrap Table</a>, loaded from a JSON file:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;table</span>
  <span class="na">id=</span><span class="s">"table"</span>
  <span class="na">data-toggle=</span><span class="s">"table"</span>
  <span class="na">data-url=</span><span class="s">"{{ '/assets/json/table_data.json' | relative_url }}"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;thead&gt;</span>
    <span class="nt">&lt;tr&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"id"</span><span class="nt">&gt;</span>ID<span class="nt">&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"name"</span><span class="nt">&gt;</span>Item Name<span class="nt">&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"price"</span><span class="nt">&gt;</span>Item Price<span class="nt">&lt;/th&gt;</span>
    <span class="nt">&lt;/tr&gt;</span>
  <span class="nt">&lt;/thead&gt;</span>
<span class="nt">&lt;/table&gt;</span>
</code></pre></div></div> <table data-toggle="table" data-url="/assets/json/table_data.json"> <thead> <tr> <th data-field="id">ID</th> <th data-field="name">Item Name</th> <th data-field="price">Item Price</th> </tr> </thead> </table> <p></p> <p>By using <a href="https://bootstrap-table.com/">Bootstrap Table</a> it is possible to create pretty complex tables, with pagination, search, and more. For example, the following HTML code will display a table, loaded from a JSON file, with pagination, search, checkboxes, and header/content alignment. For more information, check the <a href="https://examples.bootstrap-table.com/index.html">documentation</a>.</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;table</span>
  <span class="na">data-click-to-select=</span><span class="s">"true"</span>
  <span class="na">data-height=</span><span class="s">"460"</span>
  <span class="na">data-pagination=</span><span class="s">"true"</span>
  <span class="na">data-search=</span><span class="s">"true"</span>
  <span class="na">data-toggle=</span><span class="s">"table"</span>
  <span class="na">data-url=</span><span class="s">"{{ '/assets/json/table_data.json' | relative_url }}"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;thead&gt;</span>
    <span class="nt">&lt;tr&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-checkbox=</span><span class="s">"true"</span><span class="nt">&gt;&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"id"</span> <span class="na">data-halign=</span><span class="s">"left"</span> <span class="na">data-align=</span><span class="s">"center"</span> <span class="na">data-sortable=</span><span class="s">"true"</span><span class="nt">&gt;</span>ID<span class="nt">&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"name"</span> <span class="na">data-halign=</span><span class="s">"center"</span> <span class="na">data-align=</span><span class="s">"right"</span> <span class="na">data-sortable=</span><span class="s">"true"</span><span class="nt">&gt;</span>Item Name<span class="nt">&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"price"</span> <span class="na">data-halign=</span><span class="s">"right"</span> <span class="na">data-align=</span><span class="s">"left"</span> <span class="na">data-sortable=</span><span class="s">"true"</span><span class="nt">&gt;</span>Item Price<span class="nt">&lt;/th&gt;</span>
    <span class="nt">&lt;/tr&gt;</span>
  <span class="nt">&lt;/thead&gt;</span>
<span class="nt">&lt;/table&gt;</span>
</code></pre></div></div> <table data-click-to-select="true" data-height="460" data-pagination="true" data-search="true" data-toggle="table" data-url="/assets/json/table_data.json"> <thead> <tr> <th data-checkbox="true"></th> <th data-field="id" data-halign="left" data-align="center" data-sortable="true">ID</th> <th data-field="name" data-halign="center" data-align="right" data-sortable="true">Item Name</th> <th data-field="price" data-halign="right" data-align="left" data-sortable="true">Item Price</th> </tr> </thead> </table>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="tables"/><summary type="html"><![CDATA[an example of how to use Bootstrap Tables]]></summary></entry><entry><title type="html">a post with table of contents</title><link href="https://markusthill.github.io/blog/2023/table-of-contents/" rel="alternate" type="text/html" title="a post with table of contents"/><published>2023-03-20T15:59:00+00:00</published><updated>2023-03-20T15:59:00+00:00</updated><id>https://markusthill.github.io/blog/2023/table-of-contents</id><content type="html" xml:base="https://markusthill.github.io/blog/2023/table-of-contents/"><![CDATA[<p>This post shows how to add a table of contents in the beginning of the post.</p> <h2 id="adding-a-table-of-contents">Adding a Table of Contents</h2> <p>To add a table of contents to a post, simply add</p> <div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">toc</span><span class="pi">:</span>
  <span class="na">beginning</span><span class="pi">:</span> <span class="kc">true</span>
</code></pre></div></div> <p>to the front matter of the post. The table of contents will be automatically generated from the headings in the post.</p> <h3 id="example-of-sub-heading-1">Example of Sub-Heading 1</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h3 id="example-of-another-sub-heading-1">Example of another Sub-Heading 1</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h2 id="table-of-contents-options">Table of Contents Options</h2> <p>If you want to learn more about how to customize the table of contents, you can check the <a href="https://github.com/toshimaru/jekyll-toc">jekyll-toc</a> repository.</p> <h3 id="example-of-sub-heading-2">Example of Sub-Heading 2</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h3 id="example-of-another-sub-heading-2">Example of another Sub-Heading 2</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="toc"/><summary type="html"><![CDATA[an example of a blog post with table of contents]]></summary></entry><entry><title type="html">a post with giscus comments</title><link href="https://markusthill.github.io/blog/2022/giscus-comments/" rel="alternate" type="text/html" title="a post with giscus comments"/><published>2022-12-10T15:59:00+00:00</published><updated>2022-12-10T15:59:00+00:00</updated><id>https://markusthill.github.io/blog/2022/giscus-comments</id><content type="html" xml:base="https://markusthill.github.io/blog/2022/giscus-comments/"><![CDATA[<p>This post shows how to add GISCUS comments.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="external-services"/><category term="comments"/><summary type="html"><![CDATA[an example of a blog post with giscus comments]]></summary></entry></feed>